\section{Forward Process} % Seções são adicionadas para organizar sua apresentação em blocos discretos, todas as seções e subseções são automaticamente exibidas no índice como uma visão geral da apresentação, mas NÃO são exibidas como slides separados.


%----------------------------------------------------------------------------------------

\begin{frame}
	\frametitle{Forward Process' Transitions Distribution}
	
	\begin{itemize}
	\item
		\begin{align}
			q(x_t|x_{t-1}) := \mathcal{N}(x_{t}; \sqrt{1-\beta_t} \times x_{t-1}; \beta_tI)
		\end{align}
	\item \textbf{According to the original DDPM paper, the \textbf{Variance Schedule} $\beta_1, ..., \beta_T$ sequence that defines the noisy images distribution are held constant.}
	\end{itemize}
	
\end{frame}




%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------

\begin{frame}
	\frametitle{Forward Process' Transitions Distribution}
	
	\begin{itemize}
		\item
		\begin{align}
			q(x_t|x_{t-1}) := \mathcal{N}(x_{t}; \sqrt{1-\beta_t} \times x_{t-1}; \beta_tI)
		\end{align}
		\item According to the original DDPM paper, the \textbf{Variance Schedule} $\beta_1, ..., \beta_T$ sequence that defines the noisy images distribution are held constant.
		\item \textbf{Ideally, one would need a single transition from $x_0$  to get to $x_t$, with $t>0$.}
	\end{itemize}
	
\end{frame}




%----------------------------------------------------------------------------------------


%----------------------------------------------------------------------------------------

\begin{frame}
	\frametitle{Forward Process' Transitions Distribution}
	
	\begin{itemize}
		\item
		\begin{align}
			q(x_t|x_{t-1}) := \mathcal{N}(x_{t}; \sqrt{1-\beta_t} \times x_{t-1}; \beta_tI)
		\end{align}
		\item According to the original DDPM paper, the \textbf{Variance Schedule} $\beta_1, ..., \beta_T$ sequence that defines the noisy images distribution are held constant.
		\item Ideally, one would need a single transition from $x_0$  to get to $x_t$, with $t>0$.
	\textbf{\item The authors of the paper achieve such ideal scenario by defining a cumulative noise $\alpha_t$ presented in the following slide.}
	\end{itemize}
\end{frame}


%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------

\begin{frame}{Cumulative Noise}
   The Cumulative Noise ($\alpha_t$) added to an input  $x_0$ up to the t-th step is defined as:
   \begin{align}
	   	\alpha_t &:= 1 - \beta_t \\
	   	\bar{\alpha_t} &:= \prod_{s=1}^{t} a_s \\
	   	\text{which leads to}\\
	   	q(x_t|x_0) &:= \mathcal{N}(x_{t}; \sqrt{\bar{\alpha_t}} \times x_0; (1 - \bar{\alpha_t})I)
   \end{align}
\end{frame}


%----------------------------------------------------------------------------------------

\begin{frame}[fragile]
	\frametitle{Variance Scheduler Pytorch Implementation}
	
	\tiny % or \scriptsize
	\begin{python}
	class  VarianceScheduler(nn.Module):
	
		def __init__(self, T: int=1000):
			super().__init__()
			self.beta = torch.linspace(1e-4, 0.02, T, requires_grad=False)
			alpha = 1 - self.beta
			self.alpha = torch.cumprod(alpha, dim=0).requires_grad_(False)
			
		def forward(self, t):
			return self.beta[t], self.alpha[t]
	\end{python}
\end{frame}

%----------------------------------------------------------------------------------------
